<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Hongyu Qu</title>

</head>
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable">
<tr>
<td> <a href="./"><img src="./Figures/qhy.jpg" alt="" height="180px" /></a>&nbsp;</td>
<td align="left">
<p>
<font size="4"><b>Hongyu Qu (瞿宏谕)</b></font><br />
<br />
PHD Candidate<br />
<br />
School of Computer Science and Engineering <br />
Nanjing University of Science and Technology<br />
<br />
Email: quhongyu@njust.edu.cn
<br />
[<a  href="https://scholar.google.com/citations?user=X6-IzF4AAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>]
[<a  href="https://github.com/quhongyu" target="_blank">Github</a>]
</p>
</td>
</tr></table>

<h2>Biography</h2>
<p style="text-align:justify"> 
I am currently a second-year PHD candidate at Intelligent Media Analysis Group, School of Computer Science and Engineering, Nanjing University of Science and Technology, supervised by Prof. <a href="https://shuxb104.github.io/" target="_blank"> Xiangbo Shu</a>. My research interests mainly focus on Human Behavior Understanding, Embodied AI, and Data-efficient Learning.  I’m also fortunate to be co-advised by Prof. <a href="https://www.lv-lab.org/" target="_blank"> Shuicheng Yan</a> from NUS and Prof. <a href="https://sites.google.com/view/wenguanwang" target="_blank"> Wenguan Wang</a> from ZJU.
Please feel free to contact me via <a href="quhongyu@njust.edu.cn" target="_blank"> Email</a> or <a href="https://github.com/quhongyu/quhongyu.github.io/tree/main/Figures/wx.jpg" target="_blank"> WeChat</a>.

</p>

<h2>News</h2>
<ul>
<li><img src="Figures/new.gif"> <b style="color:red;">
If you are interested in collaboration or wish to get in touch with me, please feel free to contact me via <a href="quhongyu@njust.edu.cn" target="_blank"> Email</a> or <a href="https://github.com/quhongyu/quhongyu.github.io/tree/main/Figures/wx.jpg" target="_blank"> WeChat</a>. </b> (any question/suggestion/collaboration) </li>
<li>[09/2025] One paper is accepted by NeurIPS 2025. </li>
<li>[04/2025] Two paper is accepted by IJCAI 2025. </li>
<li>[01/2025] One paper is accepted by ICLR 2025. </li>
<li>[12/2024] One paper is accepted by IEEE TMM. </li>
<li>[08/2024] One paper is accepted by IEEE TMM. </li>
<li>[03/2024] One paper is accepted by IJCAI 2024. </li>
<li>[05/2023] One paper is accepted by IEEE TGRS. </li>
</ul>

    
<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications
<a style="color:Black" class="p1" href="https://scholar.google.com/citations?user=X6-IzF4AAAAJ&hl=zh-CN" target="_blank">
    <font size="2"> [Full List]</font></a> <font size="2">(^Co-first author; *Corresponding author)</font>
</h2>

<table class="imgtable">
    <tr>
    <td><img class="proj_thumb" src="./Figures/ICLR2025.png" alt="" height="90px" width="180px" />&nbsp;</td>
    <td>
    <p class="pub_title">Learning Clustering-based  Prototypes for <u>Compositional Zero-shot Learning</u></p>
    <p class="pub_author"><b>Hongyu Qu</b>, Jianan Wei, Xiangbo Shu*, Wenguan Wang<br>
        International Conference on Learning Representations (<b>ICLR</b>), 2025.<br>
    [<a href="https://arxiv.org/pdf/2502.06501" target="_blank">Paper</a>]
    </p> </td>
    </tr>

    <table class="imgtable">
        <tr>
        <td><img class="proj_thumb" src="./Figures/NeurIPS2025.png" alt="" height="90px" width="180px" />&nbsp;</td>
        <td>
        <p class="pub_title">OmniGaze: Reward-inspired Generalizable Gaze Estimation in the Wild</u></p>
        <p class="pub_author"><b>Hongyu Qu</b>, Jianan Wei, Xiangbo Shu*, Yazhou Yao, Wenguan Wang*, Jinhui Tang<br>
            Annual Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2025.<br>
        [<a>Paper</a>]
        </p> </td>
        </tr>


<table class="imgtable">
<tr>
<td><img class="proj_thumb" src="./Figures/TMM2024.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">MVP-Shot: Multi-Velocity Progressive-Alignment Framework for <u>Few-Shot Action Recognition</u></p>
<p class="pub_author"><b>Hongyu Qu</b>, Rui Yan, Xiangbo Shu*, Hailiang Gao, Peng Huang, Guosen Xie<br>
    IEEE Transactions on Multimedia (<b>TMM</b>), 2025.<br>
[<a href="https://arxiv.org/pdf/2405.02077" target="_blank">Paper</a>]
</p> </td>
</tr>

<table class="imgtable">
    <tr>
    <td><img class="proj_thumb" src="./Figures/IJCAI2025_YR.png" alt="" height="90px" width="180px" />&nbsp;</td>
    <td>
    <p class="pub_title">TEST-V: TEst-time Support-set Tuning for <u>Zero-shot Video Classification</u></p>
    <p class="pub_author">Rui Yan, Jin Wang^, <b>Hongyu Qu</b>, Xiaoyu Du, Dong Zhang, Jinhui Tang, Tieniu Tan<br>
        International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2025.<br>
    [<a href="https://arxiv.org/pdf/2502.00426" target="_blank">Paper</a>]
    </p> </td>
    </tr>

    <table class="imgtable">
        <tr>
        <td><img class="proj_thumb" src="./Figures/IJCAI25_GWX.png" alt="" height="90px" width="180px" />&nbsp;</td>
        <td>
        <p class="pub_title">Reliable and Diverse Hierarchical Adapter for <u>Zero-shot Video Classification</u></p>
        <p class="pub_author">Wenxuan Ge, Peng Huang^, Rui Yan*, <b>Hongyu Qu</b>, Guosen Xie, Xiangbo Shu*<br>
            International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2025.<br>
        [<a href="https://arxiv.org/pdf/2502.00426" target="_blank">Paper</a>]
        </p> </td>
        </tr>

<table class="imgtable">
    <tr>
    <td><img class="proj_thumb" src="./Figures/TMM2024_ghl.png" alt="" height="90px" width="180px" />&nbsp;</td>
    <td>
    <p class="pub_title">Hierarchical Motion-Enhanced Matching Framework for <u>Few-shot Action Recognition</u></p>
    <p class="pub_author">Hailiang Gao, Guosen Xie, Rui Yan, Qiongjie Cui, <b>Hongyu Qu</b>, Xiangbo Shu*<br> 
    IEEE Transactions on Multimedia (<b>TMM</b>), 2024.<br>
    [<a href="https://ieeexplore.ieee.org/abstract/document/10812791/" target="_blank">Paper</a>]
    </p> </td>
    </tr>

<tr>
<td><img class="proj_thumb" src="./Figures/IJCAI2024.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">DTS-TPT: Dual Temporal-Sync Test-time Prompt Tuning for <u>Zero-shot Activity Recognition</u></p>
<p class="pub_author">Rui Yan, <b>Hongyu Qu</b>^, Xiangbo Shu, Wenbin Li*, Jinhui Tang, Tieniu Tan<br>
International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2024.<br>
[<a href="https://www.ijcai.org/proceedings/2024/0170.pdf" target="_blank">Paper</a>]
</tr>

<tr>
<td><img class="proj_thumb" src="./Figures/TGRS2022.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">CLEGAN: <u>Toward Low-Light Image Enhancement</u> for UAVs via Self-Similarity Exploitation</p>
<p class="pub_author">Ling Xing, <b>Hongyu Qu</b>^, Sheng Xu*, Yao Tian<br>
IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2023.<br>
[<a href="https://ieeexplore.ieee.org/abstract/document/10136217" target="_blank">Paper</a>] 
</p> </td>
</tr>
<table>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Professional Services</h2>

<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Information Forensics and Security (TIFS) </li>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </li>
<li>IEEE Transactions on Multimedia (TMM) </li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </li>
<li>The Visual Computer (TVCJ) </li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>Annual Conference on Neural Information Processing Systems (NeurIPS 2025) </li>
<li>International Conference on Learning Representations (ICLR 2025-2026)</li>
<li>AAAI Conference on Artificial Intelligence (AAAI 2026) </li>
<li>International Joint Conference on Artificial Intelligence (IJCAI 2025) </li>
<li>ACM International Conference on Multimedia (ACM MM 2025) </li>
<li>EEE International Conference On Multimedia & Expo (ICME 2025) </li>
</ul>
</font>
<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
